{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ-zfi6HcWq-"
      },
      "source": [
        "<h2>Soru 1</h2>\n",
        "<h3>One hot encoding modelin görmediği veriye nasıl uygulanır?</h3>\n",
        "\n",
        "Modelin görmediği veriye, validation ya da test (farklı kaynaklarda birbirlerinin yerlerine kullanılabiliyor), eğitim sırasında sanki hiç elimizde öyle bir veri yokmuş gibi davranmak isteriz, dışlarız onu. Fakat, train setine yapılan tüm dönüşümler her ne olursa olsun, tahminlerde bulunmadan önce test setine de yapılmalıdır. Bu dönüşümler ayrı ayrı gerçekleştirilmelidir, buradaki kilit nokta budur.\n",
        "\n",
        "Örneğin, test setinde kategorilerden biri eksikse, eğittiğimiz model yine de o dummy değişkeni bekleyeceğinden, eksik kategori için (eğitim setinde bulunabilecek) bir dummy değişken olmalıdır. Test setinin fazladan bir kategorisi varsa, bu muhtemelen bazı \"diğer\" kategorilerle ele alınmalıdır. Örnek bir kod bloğu aşağıda yer almaktadır.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xZj5tjGcZ5t",
        "outputId": "c8aa8482-b46c-4199-dff7-0ef7d7fefe4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yanlış yaklaşılan one-hot encoding\n",
            "**************************************************\n",
            "Traing seti :\n",
            " [[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]]\n",
            "\n",
            "Test seti :\n",
            " [[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]] \n",
            "\n",
            "\n",
            "Doğru yaklaşılan one-hot encoding\n",
            "**************************************************\n",
            "Traing seti :\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]] \n",
            "\n",
            "Test seti :\n",
            " [[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "train = pd.DataFrame(['A', 'B', 'A', 'C'])\n",
        "test = pd.DataFrame(['B', 'A', 'D'])\n",
        "\n",
        "full = pd.concat((train, test))\n",
        "\n",
        "enc_false = OneHotEncoder(handle_unknown = 'ignore')\n",
        "enc_false.fit(full)\n",
        "\n",
        "print('Yanlış yaklaşılan one-hot encoding')\n",
        "print('*'*50)\n",
        "print(f'Traing seti :\\n {enc_false.transform(train).toarray()}\\n')\n",
        "print(f'Test seti :\\n {enc_false.transform(test).toarray()} \\n\\n')\n",
        "\n",
        "enc_true = OneHotEncoder(handle_unknown = 'ignore')\n",
        "enc_true.fit(train)\n",
        "print('Doğru yaklaşılan one-hot encoding')\n",
        "print('*'*50)\n",
        "print(f'Traing seti :\\n {enc_true.transform(train).toarray()} \\n')\n",
        "print(f'Test seti :\\n {enc_true.transform(test).toarray()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C61nkLMzcd5b"
      },
      "source": [
        "<br>\n",
        "Yanlış yaklaşımda D için fazladan bir sütun olduğu dikkatimizi çekiyor. Eğitim sırasında D'yi hiç bilemeyeceğiz, bu yüzden onun için bir sütun olmamalı.\n",
        "\n",
        "Burada önemli olan bir nokta da <b>handle_unknown</b> parametresidir. Bu parametre dönüştürme sırasında bilinmeyen bir kategorik özellik varsa bir hatanın oluşturulup oluşturulmayacağı veya yoksayılacağını belirlemek içindir. Eğer parametre <b>'ignore'</b> ayarlandıysa ve dönüştürme işlemi sırasında bilinmeyen bir kategori ile karşılaşılırsa, bu özellik için elde edilen one-hot kodlanmış sütunların tümü sıfır olacaktır. Hemen bunu da bir örnek ile açıklayalım.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "pOUY7JPhciOv",
        "outputId": "e0045c5b-287a-4645-f45a-659cfc79f8f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>HP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2008</td>\n",
              "      <td>280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GTR</td>\n",
              "      <td>2015</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SUPRA</td>\n",
              "      <td>2001</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2010</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Year   HP\n",
              "0    EVO  2008  280\n",
              "1    GTR  2015  500\n",
              "2  SUPRA  2001  240\n",
              "3    EVO  2010  300"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {'Model': ['EVO', 'GTR', 'SUPRA', 'EVO'],\n",
        "        'Year' : [2008, 2015, 2001, 2010], \n",
        "        'HP' : [280, 500, 240, 300]}\n",
        "jdm_train = pd.DataFrame(data)\n",
        "jdm_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEPjvacZclIX"
      },
      "source": [
        "<br>\n",
        "Yukarıdaki veri setinin bizim train setimiz olduğunu düşünelim. <b>Model</b> kategorik bir değişken, dolayısıyla ona One-Hot Encoding uygulayabiliriz.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Aw171lCTcnQH",
        "outputId": "b93a9177-85b2-4105-ee8c-bf50e2c45a59"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>HP</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2008</td>\n",
              "      <td>280</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GTR</td>\n",
              "      <td>2015</td>\n",
              "      <td>500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SUPRA</td>\n",
              "      <td>2001</td>\n",
              "      <td>240</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2010</td>\n",
              "      <td>300</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Year   HP    0    1    2\n",
              "0    EVO  2008  280  1.0  0.0  0.0\n",
              "1    GTR  2015  500  0.0  1.0  0.0\n",
              "2  SUPRA  2001  240  0.0  0.0  1.0\n",
              "3    EVO  2010  300  1.0  0.0  0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "enc_fit = enc.fit(jdm_train[['Model']])\n",
        "enc_fit_df = pd.DataFrame(enc_fit.fit_transform(jdm_train[['Model']]))\n",
        "jdm_train = jdm_train.join(enc_fit_df)\n",
        "jdm_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcSejZYscox_"
      },
      "source": [
        "<br>\n",
        "Bu işlemden sonra bir test verisi ayarlayalım ve onu encode edelim. Yukarıdaki yaptığımız işlem sonucunda, test setimizde yer alan ve train setinde hiç olmamış olan verilere 0 atadığını görmeyi umuyoruz.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ydar1Kbkcr9z",
        "outputId": "843f581f-687a-403e-f13d-c6693cccb268"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>HP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2010</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NSX</td>\n",
              "      <td>2000</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Silva</td>\n",
              "      <td>1999</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Year   HP\n",
              "0    EVO  2010  300\n",
              "1    NSX  2000  250\n",
              "2  Silva  1999  200"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test = {'Model' : ['EVO', 'NSX', 'Silva'],\n",
        "             'Year': [2010, 2000, 1999],\n",
        "             'HP' : [300, 250, 200]}\n",
        "\n",
        "jdm_test = pd.DataFrame(data_test)\n",
        "jdm_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tKtg44vcuH_"
      },
      "source": [
        "<br>\n",
        "Oluşturduğumuz test verisinde 1. ve 2. indexe sahip değerlerin <b>Model</b> değişkeni train setimizde hiç yoktu. Bu setimizi train setimizle fit ettiğimiz değişken ile <b>(enc_fit)</b> encode edelim.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "h3VR8RyCcv69",
        "outputId": "9e642d47-264d-4f7f-9c15-7766ddf3c275"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>HP</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EVO</td>\n",
              "      <td>2010</td>\n",
              "      <td>300</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NSX</td>\n",
              "      <td>2000</td>\n",
              "      <td>250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Silva</td>\n",
              "      <td>1999</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Year   HP    0    1    2\n",
              "0    EVO  2010  300  1.0  0.0  0.0\n",
              "1    NSX  2000  250  0.0  0.0  0.0\n",
              "2  Silva  1999  200  0.0  0.0  0.0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_fit_test = pd.DataFrame(enc_fit.transform(jdm_test[['Model']]))\n",
        "jdm_test = jdm_test.join(enc_fit_test)\n",
        "jdm_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_wNDnMGcxUg"
      },
      "source": [
        "<br>\n",
        "Bilinmeyen tüm kategorileri aynı şekilde kodlandığını görmüş olduk. Bu, bilinmeyen kategorilerden yeni bir kategori tanımlandığı anlamına gelmektedir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kem1sCD9c0uE"
      },
      "source": [
        "<br>\n",
        "<h2>Soru 2</h2>\n",
        "<h3>Labelencoding'de ilgili kolon için ölçeklendirme nasıl yapılır? (Verinin doğru etkisiyle sayısal olarak dönüştürülmesi)</h3>\n",
        "\n",
        "Python'da Label Encoding işleminde, kategorik değişkeni 0 ile sınıf sayısı eksi 1 değerleri ile değiştiririz. Örneğin 5 adet kategorik değişkenimiz varsa biz bunlar için 0,1,2,3,4 değerlerini kullanırız.\n",
        "\n",
        "Bunu daha iyi anlamak için aşağıda Hindistan'da ki Covid-19 vakalarına ait verileri inceleyelim. Verileri incelediğimizde göze direkt olarak çarpıyor ki <b>State</b> kolonu kategorik veriler içermektedir ve diğer veriler ise nümeriktir. O zaman State kolonuna Label kodlaması yapmalıyız.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1jETgcUc2wh"
      },
      "source": [
        "<img src = 'https://lh4.googleusercontent.com/1mpZdH8WhawXeJ-7Vursq-84VSNI1wIMuZ0JeZxs1N82HMUExYmBhVHlW_QvVySeUoxX9ABLyjU5y80C8NChpez4rYvzJC14wlG7xpQI8w0vBlxLVsTww8VQoyo2f-7o4HRnQmlCMKNuvXvvGw'></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVjc7pHc66F"
      },
      "source": [
        "<br>\n",
        "Aşağıdaki görseli incelersek, Label Encoding'den sonra kategorik değerlerin her birisine sayısal bir değer atandığını görürüz. Bu sayısal değerlerin neden sırasıyla 0,1,2 ya da 5,4,3 gibi atanmadığını merak ediyoruz. Cevap ise basit, atamalar alfabetik şekilde gerçekleştiriliyor, aynen bu kadar.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrsW-DY3c89b"
      },
      "source": [
        "<img src = 'https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/08/11155757/image-37.png'></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlJzDbQCdAoP"
      },
      "source": [
        "<br>\n",
        "<h3>Python ile Label Encoding</h3>\n",
        "\n",
        "<ol>\n",
        "    <li>Öncelikle Label Encoding işleminde kullancağımız Pandas ve NumPy kütüphanelerini import edelim.</li>\n",
        "    <li>Ardından Pandas yardımıyla veri setimizi okuyacağız ve sonrasında verilerin düzgün yüklenip yüklenmediğini info() metoduyla inceleyeceğiz. State verisinin nesne tipinde olduğunu görebiliyoruz, bu adımdan sonra Label Encoding'e geçebiliriz.</li>\n",
        "</ol>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20g6_9RdDwi",
        "outputId": "1bcb4b6b-7be9-48f6-edba-e53213396724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  6 non-null      int64 \n",
            " 1   State       6 non-null      object\n",
            " 2   Confimed    6 non-null      int64 \n",
            " 3   Deaths      6 non-null      int64 \n",
            " 4   Recovered   6 non-null      int64 \n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 368.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "# Pandas ve NumPy'ı import etme\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Verilerimizin olduğu csv dosyasını okuyup bir dataframe'e aktarma\n",
        "covid19 = pd.read_csv('/covid19_india.csv')\n",
        "\n",
        "# Verisetimizin içeriğini inceleme\n",
        "covid19.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJ_SmgYdVed"
      },
      "source": [
        "<br>\n",
        "Label Encoding iki şekilde gerçekleştirilebilir:\n",
        "<li>Scikit-learn kütüphanesinde bulunan LabelEncoder sınıfını</li>\n",
        "<li>Kategori kodları</li>\n",
        "\n",
        "<h4>1. Scikit-learn Yaklaşımı</h4>\n",
        "\n",
        "Öncelikle ilgili sınıfı kütüphaneden import ederiz.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mWBOadCTddpO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GwZnExEde8_"
      },
      "source": [
        "<br>\n",
        "Ardından sırasıyla:\n",
        "<ol>\n",
        "<li>İlk olarak LabelEncoder() sınıfından bir labelencoder değişkeni/nesnesi türetilir.</li>\n",
        "<li>Ardından kategorik değişkene sayısal değer atayan fit_transform yapılır ve oluşturulan sayısal değerler, yeni yaratılan 'State_N' kolonunda saklanır.</li>\n",
        "<li>Unutulmaması gereken nokta, State adlı sütunu sayısal ifadeye dönüştürdük ve bu değerleri State_N sütununa aktardık. Fakat State sütunu hala veri setimizin içerisinde yer almaktadır. Veri seti ile modeli beslemeden önce State sütununun kaldırılması gerektiği unutulmamalıdır.</li>\n",
        "</ol>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xl_LEIlIdkE2",
        "outputId": "af74f97d-61ff-44cb-9911-71443bc2a6af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>State</th>\n",
              "      <th>Confimed</th>\n",
              "      <th>Deaths</th>\n",
              "      <th>Recovered</th>\n",
              "      <th>State_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Maharashtra</td>\n",
              "      <td>284281</td>\n",
              "      <td>11194</td>\n",
              "      <td>158140</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Tamil Nadu</td>\n",
              "      <td>156369</td>\n",
              "      <td>2568</td>\n",
              "      <td>107416</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>118645</td>\n",
              "      <td>2031</td>\n",
              "      <td>116785</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Karnataka</td>\n",
              "      <td>51422</td>\n",
              "      <td>1235</td>\n",
              "      <td>40356</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Gujarat</td>\n",
              "      <td>45481</td>\n",
              "      <td>1046</td>\n",
              "      <td>42336</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Uttar Pradesh</td>\n",
              "      <td>42023</td>\n",
              "      <td>1022</td>\n",
              "      <td>41956</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0          State  Confimed  Deaths  Recovered  State_N\n",
              "0           0    Maharashtra    284281   11194     158140        3\n",
              "1           1     Tamil Nadu    156369    2568     107416        4\n",
              "2           2          Delhi    118645    2031     116785        0\n",
              "3           3      Karnataka     51422    1235      40356        2\n",
              "4           4        Gujarat     45481    1046      42336        1\n",
              "5           5  Uttar Pradesh     42023    1022      41956        5"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#LabelEncoder örneği oluşturma\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "#Fit_transform ile kategorik değişkenleri sayısal değerler ile etiketleme ve bunu yeni kolonda (State_N) saklama\n",
        "covid19['State_N'] = labelencoder.fit_transform(covid19['State'])\n",
        "\n",
        "#Veri setini ekrana yazırma\n",
        "covid19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-1YZtgjdiiS"
      },
      "source": [
        "<br>\n",
        "<h4>2. Kategori Kodları Yaklaşımı</h4>\n",
        "<ol>\n",
        "<li>Öncelikle nesne tipinde olan State verilerini kategori tipine çeviririz.</li>\n",
        "<li>Kategorilerin kodlarına da <b>covid19['State'].cat.codes</b> ile ulaşabiliriz.</li>\n",
        "</ol>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIm59Um3drpF",
        "outputId": "61b6fdcb-93d1-4273-b498-4a5ec6964935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0       int64\n",
              "State         category\n",
              "Confimed         int64\n",
              "Deaths           int64\n",
              "Recovered        int64\n",
              "State_N          int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid19['State'] = covid19['State'].astype('category')\n",
        "covid19.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "23bRUX6mduq_",
        "outputId": "a7aa0c5b-15f7-4b17-b6e3-fd61aeb55441"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>State</th>\n",
              "      <th>Confimed</th>\n",
              "      <th>Deaths</th>\n",
              "      <th>Recovered</th>\n",
              "      <th>State_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>284281</td>\n",
              "      <td>11194</td>\n",
              "      <td>158140</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>156369</td>\n",
              "      <td>2568</td>\n",
              "      <td>107416</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>118645</td>\n",
              "      <td>2031</td>\n",
              "      <td>116785</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>51422</td>\n",
              "      <td>1235</td>\n",
              "      <td>40356</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>45481</td>\n",
              "      <td>1046</td>\n",
              "      <td>42336</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>42023</td>\n",
              "      <td>1022</td>\n",
              "      <td>41956</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  State  Confimed  Deaths  Recovered  State_N\n",
              "0           0      3    284281   11194     158140        3\n",
              "1           1      4    156369    2568     107416        4\n",
              "2           2      0    118645    2031     116785        0\n",
              "3           3      2     51422    1235      40356        2\n",
              "4           4      1     45481    1046      42336        1\n",
              "5           5      5     42023    1022      41956        5"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid19['State'] = covid19['State'].cat.codes\n",
        "covid19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9y2FTzFdZ3d"
      },
      "source": [
        "<br>\n",
        "Bu işlemlerden sonra potansiyel olarak bir sorun ortaya çıkmaktadır. Genellikle kategorik veriler arasında herhangi bir ilişki bulunmaz fakat bizim öğrenme algoritmalarımız sayılar arasında bir ilişki kurar. Label encoding işlemi sonrasında ise algoritmanın ilişki kurabileceği türden bir etiketleme yaptığını görebiliyoruz. Her bir state için farklı sayısal değerler üretti fakat bu değerler birbirleriyle kıyaslanabilir, dolayısıyla algoritma da kıyaslayacaktır fakat bu etiket değerlerinin State'lere ait olduğunu, kıyaslanamayacağını biz biliyoruz, algoritma bilmiyor. Label Encoding'de ki genel sorun bu.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvRFkh9idaMM"
      },
      "source": [
        "<br>\n",
        "<h2>Soru 3</h2>\n",
        "<h3>Imbalance datasette train test split yaparken neleri göz önünde bulundurmalıyız?</h3>\n",
        "\n",
        "Yüzde 90'ı A, yüzde 10'u B etiketi gibi olan dengesiz veri setlerinde train/test splitting adımına dikkat etmemiz gerekmektedir. Dikkat edeceğimiz noktalar:\n",
        "<li>Elimizdeki setleri, test setinin tüm sette aynı oranda sahip olacak şekilde bölmemiz gerekmektedir. Aksi takdirde, tamamen rastgele olacak şekilde test setimiz tamamen A'lardan oluşabilir ve bu durumda modelimiz yalnızca A'ları tahmin edebilir. Doğru oranları düzenlediğimiz takdirde modelimiz B'leri de tahmin edebilir. </li>\n",
        "<li>Eğitim adil olabilmesi için azınlıkta olan sınıfa daha <b>fazla örnekleme (oversampling)</b>, ya da fazlalık olan sınıfa <b>eksik örnekleme (undersampling)</b> yapılabilir.</li>\n",
        "<li>Sadece <b>accuracy</b> değerini değil, aynı zamanda <b>precision</b> ve <b>recall</b> değerlerini de ölçmemiz, bunlara dikkat etmemiz gerekmektedir. Berbat bir model kurduk diyelim ve bu model tüm örneklerin A olduğunu söylüyor. Bu, modelin %90 doğru olduğu anlamına gelmiyor, elindeki verilerin yüzde 90'nı A olduğu için zıt görüş hakkında bilgisi olmuyor. Dolayısıyla ne gelirse gelsin yüzde 90 ihtimalle A olmuş oluyor model için. Bu sebeple elimizde olan diğer metrikler fazlasıyla önem arzediyor ve onları dikkate almamız gerekiyor.</li>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5s-HE-Dd65S"
      },
      "source": [
        "<br>\n",
        "<h2>Soru 4</h2>\n",
        "<h3> Validation dataseti (modelin görmediği) nasıl oluşturulur ve nasıl predict etmeye hazır hale getirilir?</h3>\n",
        "\n",
        "Modeli oluşturmak veya ince ayarlar yapmak için modelin kullanılmayan örnekler üzerinde değerlendirilmesi ideal olandır ve bu şekilde tarafsız bir yöntem sağlanmış olur. Validation setindeki bilgilerin, tüm model ayarlamaları tamamlanana kadar saklanması yani, validation setinin kitlenmesi gerekmektedir. Validation seti, en başta hiçbir işlem görmeden önce ayrılmalıdır, daha sonrasında model kurma aşamasında gereken tüm testler, test seti üzerinde gerçekleştirilir. Model kurma aşaması tamamlandıktan sonra son olarak validation seti ile modelin gerçek hayattaki potansiyeli ölçülür. Bu ölçümü yapabilmek için validation setine, train setinden ayrı olarak yine train setine yapılan tüm işlemlerin yapılması gerekmektedir. Burada dikkat edilecek husus ise, train setine yapılan encoding işlemleri sonucunda çıkan veriler ile validation setinde gerçekleştiren encoding işlemi sonucunda çıkan verilerin birbirleriyle uyuşması. Bunun için gerekli yöntemler de gerçekleştirildiği takdirde validation setimiz predict etmeye hazır hale gelmiş olacaktır.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-kyxIneBhi"
      },
      "source": [
        "<br>\n",
        "<h2>Soru 5</h2>\n",
        "<h3>'predict_proba' Metoduyla Oran Nasıl Hesaplanır ve Treshold Nasıl Değiştirilir?</h3>\n",
        "\n",
        "Sınıflandırma, kümeleme, regresyon gibi yöntemlerin kullanıldığı çalışmalarda tahmin edilen etiket bilgisi <b>predict</b> fonksiyonu ile hesaplanırken, sınıflandırma problemlerinde gözlemlerin sınıflara ait olma olasılıkları ise <b>predict_proba</b> fonksiyonu ile hesaplanır.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vo8rPkleK8u"
      },
      "outputs": [],
      "source": [
        "# dt, DecisionTreeClassifier sınıfından türetilen değişken\n",
        "y_pred_proba = dt.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuN2M6cJeHLb"
      },
      "source": [
        "<br>\n",
        "Yukarıda yer alan örnekteki gibi çalışan predict_proba ile etiketleri değil olasılıkları öğreniriz, çıktıda yer alan veriler de her etikete ait olma yüzdesini içerir. \n",
        "\n",
        "Kullandığımız predict_proba fonksiyonu ile thresold'a istediğimiz bir değeri nasıl verebiliriz onu inceleyelim.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1Ju3LWheRzK"
      },
      "outputs": [],
      "source": [
        "#Threshold değerini değiştirme\n",
        "y_pred_new_threshold = (model.predict_proba() >= mythreshold).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EfuYUueUcQ"
      },
      "source": [
        "<br>\n",
        "Yukarıdaki yer alan kod parçacığını incelediğimizde, predict_proba'nın çıktıları ile ufak bir threshold kontrolü yaparak '>=' istediğimiz threshold değerlerini elde ediyoruz. Fakat burada eksik olan bir şey var, predict_proba fonksiyonunun çıktısı (n_data_rows, n_classes) şeklinde bir dizidir. Eğer yukarıdaki gibi çalıştırırsak hedef sınıfa uygulamış olmayız, o yüzden hedef sınıfı belirtmemiz gerekmektedir (genellikle 1).\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cub6e-_Ueaf-"
      },
      "outputs": [],
      "source": [
        "#Threshold değerini değiştirme\n",
        "y_pred_new_threshold = (model.predict_proba()[:,1] >= mythreshold).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R95BgF7HebZA"
      },
      "source": [
        "<br>\n",
        "<h2>Soru 6</h2>\n",
        "<h3 align='justify'>Fraud case'i üzerinde train&test&validation split, encoding, scaling,modelleme çalışmaları Python'da yapılarak, modelin görmediği dataset üzerinde başarılı sonuç alacak bir model örneği yapılmalı.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qNffBVpAlp6f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "#for quick viz\n",
        "import seaborn as sns\n",
        "\n",
        "#ml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K2aWN0EtlstJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/var/auto_insurance_csv.csv')\n",
        "df = df.drop(['_c39','Unnamed: 0'], axis = 1)\n",
        "df['umbrella_limit'] = df.umbrella_limit.fillna(\"9999\")\n",
        "df['police_report_available'] = df.police_report_available.fillna(\"MISSING\")\n",
        "df['policy_csl'] = df.policy_csl.fillna(\"MISSING\")\n",
        "df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'])\n",
        "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
        "df['claim_day_of_policy'] = (df.incident_date -  df.policy_bind_date).dt.days\n",
        "df['location_check'] = np.nan\n",
        "df['location_check'] = np.where(df['policy_state'] == df['incident_state'], True, False)\n",
        "df['fraud_reported'] = df['fraud_reported'].str.replace('Y', '1')\n",
        "df['fraud_reported'] = df['fraud_reported'].str.replace('N', '0')\n",
        "df['fraud_reported'] = df['fraud_reported'].astype(int)\n",
        "df['umbrella_limit'] = df.umbrella_limit.astype(str)\n",
        "umbrealla = df['umbrella_limit'].unique()\n",
        "for umb in umbrealla:\n",
        "  if (umb != '0.0') & (umb != '9999'):\n",
        "    df['umbrella_limit'] = df['umbrella_limit'].str.replace(umb, 'other')\n",
        "    \n",
        "hobbies = df['insured_hobbies'].unique()\n",
        "for hobby in hobbies:\n",
        "  if (hobby != 'chess') & (hobby != 'cross-fit'):\n",
        "    df['insured_hobbies'] = df['insured_hobbies'].str.replace(hobby, 'other')\n",
        "\n",
        "df['age'] = df.age.fillna(9999)\n",
        "bin_labels = ['15-20', '21-25', '26-30', '31-35', '36-40', '41-45', '46-50', '51-55', '56-60', '61-65','9999']\n",
        "bins = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 9999]\n",
        "\n",
        "df['age_group'] = pd.cut(df['age'], bins = bins, labels = bin_labels, include_lowest = True)\n",
        "bins = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "bin_labels = ['0-50','51-100','101-150','151-200','201-250','251-300','301-350','351-400','401-450','451-500']\n",
        "\n",
        "df['months_as_customer_groups'] = pd.cut(df['months_as_customer'], bins = 10, labels = bin_labels, include_lowest= True)\n",
        "bins = list(np.linspace(0,2500, 6, dtype = int))\n",
        "bin_labels = ['very low', 'low', 'medium', 'high', 'very high']\n",
        "\n",
        "df['policy_annual_premium_groups'] = pd.cut(df['policy_annual_premium'], bins = bins, labels=bin_labels)\n",
        "bins = list(np.linspace(0,2000, 5, dtype = int))\n",
        "bin_labels = ['0-500', '501-1000', '1001-1500', '1501-2000']\n",
        "\n",
        "df['policy_deductable_group'] = pd.cut(df['policy_deductable'], bins = bins, labels = bin_labels)\n",
        "\n",
        "df = df.drop(['age', 'months_as_customer', 'policy_deductable', 'policy_annual_premium'], axis = 1)\n",
        "required_columns = ['incident_date','policy_state', 'policy_csl', 'umbrella_limit',\n",
        "       'insured_zip', 'insured_sex', 'insured_education_level',\n",
        "       'insured_occupation', 'insured_hobbies', 'insured_relationship',\n",
        "       'capital-gains', 'capital-loss', 'incident_type', 'collision_type',\n",
        "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
        "       'incident_city', 'incident_location', 'incident_hour_of_the_day',\n",
        "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
        "       'witnesses', 'police_report_available', 'total_claim_amount','auto_make',\n",
        "       'auto_model', 'auto_year', 'fraud_reported', 'claim_day_of_policy',\n",
        "       'location_check', 'age_group', 'months_as_customer_groups',\n",
        "       'policy_annual_premium_groups', 'policy_deductable_group']\n",
        "df1 = df[required_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rve1N-S1mveK",
        "outputId": "a62d88e9-c2fc-4e88-eae0-5a6a557abfa5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.incident_date.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7P2L12Nlm0IH"
      },
      "outputs": [],
      "source": [
        "# Validation ve model setlerinin belirlenmesi\n",
        "df1_val = df1.sort_values(by='incident_date',ascending=False).head(200)\n",
        "df1_model = df1.sort_values(by='incident_date',ascending=False).tail(800)\n",
        "\n",
        "# Gereksiz iki kolonun temizlenmesi\n",
        "df1_val = df1_val.drop([\"incident_date\"],axis=1)\n",
        "df1_model = df1_model.drop([\"incident_date\"],axis=1)\n",
        "df1_val = df1_val.drop([\"incident_location\"],axis=1)\n",
        "df1_model = df1_model.drop([\"incident_location\"],axis=1)\n",
        "\n",
        "# Kategorik kolonların belirlenmesi\n",
        "cat_cols = ['age_group', 'months_as_customer_groups', 'policy_annual_premium_groups','location_check','policy_deductable_group']\n",
        "for col in cat_cols:\n",
        "  df1_model[col] = df1_model[col].astype('object')\n",
        "\n",
        "#Encode edilecek olan kolonların oluşturulan listeye kaydedilmesi\n",
        "columns_to_encode = []\n",
        "for col in df1_model.columns:\n",
        "  if df1_model[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)\n",
        "\n",
        "#Kategorik değişkenler üzerinde dummy dönüşümü gerçekleştirimi\n",
        "df1_model_dummy = pd.get_dummies(df1_model, columns = columns_to_encode)\n",
        "columns_dummy = []\n",
        "for i in df1_model_dummy.columns:\n",
        "    columns_dummy.append(i)\n",
        "\n",
        "df1_dummy = df1_model_dummy.iloc[:,:11]\n",
        "clmn_dummy= columns_dummy[11:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXONwZ8_pXfc"
      },
      "source": [
        "<br>\n",
        "Yukarıda model kuracağımız set ile validation setini ilk olarak ayırıyoruz. Validation setimizi kitleyerek, model için hazırladığımız veriler üzerinden kategorik verileri tespit ediyoruz, bu verilere sonrasında one-hot dönüşümü yapılacak.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "LO2-_NKeMNq7",
        "outputId": "ad0e2062-1087-4007-ba53-af922d260c01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "      <th>claim_day_of_policy</th>\n",
              "      <th>policy_state_IL</th>\n",
              "      <th>policy_state_IN</th>\n",
              "      <th>policy_state_OH</th>\n",
              "      <th>policy_csl_100/300</th>\n",
              "      <th>policy_csl_250/500</th>\n",
              "      <th>policy_csl_500/1000</th>\n",
              "      <th>policy_csl_MISSING</th>\n",
              "      <th>umbrella_limit_0.0</th>\n",
              "      <th>umbrella_limit_9999</th>\n",
              "      <th>umbrella_limit_other</th>\n",
              "      <th>insured_sex_FEMALE</th>\n",
              "      <th>insured_sex_MALE</th>\n",
              "      <th>insured_education_level_Associate</th>\n",
              "      <th>insured_education_level_College</th>\n",
              "      <th>insured_education_level_High School</th>\n",
              "      <th>insured_education_level_JD</th>\n",
              "      <th>insured_education_level_MD</th>\n",
              "      <th>insured_education_level_Masters</th>\n",
              "      <th>insured_education_level_PhD</th>\n",
              "      <th>insured_occupation_adm-clerical</th>\n",
              "      <th>insured_occupation_armed-forces</th>\n",
              "      <th>insured_occupation_craft-repair</th>\n",
              "      <th>insured_occupation_exec-managerial</th>\n",
              "      <th>insured_occupation_farming-fishing</th>\n",
              "      <th>insured_occupation_handlers-cleaners</th>\n",
              "      <th>insured_occupation_machine-op-inspct</th>\n",
              "      <th>insured_occupation_other-service</th>\n",
              "      <th>insured_occupation_priv-house-serv</th>\n",
              "      <th>insured_occupation_prof-specialty</th>\n",
              "      <th>...</th>\n",
              "      <th>auto_model_RAM</th>\n",
              "      <th>auto_model_RSX</th>\n",
              "      <th>auto_model_Silverado</th>\n",
              "      <th>auto_model_TL</th>\n",
              "      <th>auto_model_Tahoe</th>\n",
              "      <th>auto_model_Ultima</th>\n",
              "      <th>auto_model_Wrangler</th>\n",
              "      <th>auto_model_X5</th>\n",
              "      <th>auto_model_X6</th>\n",
              "      <th>location_check_False</th>\n",
              "      <th>location_check_True</th>\n",
              "      <th>age_group_15-20</th>\n",
              "      <th>age_group_21-25</th>\n",
              "      <th>age_group_26-30</th>\n",
              "      <th>age_group_31-35</th>\n",
              "      <th>age_group_36-40</th>\n",
              "      <th>age_group_41-45</th>\n",
              "      <th>age_group_46-50</th>\n",
              "      <th>age_group_51-55</th>\n",
              "      <th>age_group_56-60</th>\n",
              "      <th>age_group_61-65</th>\n",
              "      <th>age_group_9999</th>\n",
              "      <th>months_as_customer_groups_0-50</th>\n",
              "      <th>months_as_customer_groups_101-150</th>\n",
              "      <th>months_as_customer_groups_151-200</th>\n",
              "      <th>months_as_customer_groups_201-250</th>\n",
              "      <th>months_as_customer_groups_251-300</th>\n",
              "      <th>months_as_customer_groups_301-350</th>\n",
              "      <th>months_as_customer_groups_351-400</th>\n",
              "      <th>months_as_customer_groups_401-450</th>\n",
              "      <th>months_as_customer_groups_451-500</th>\n",
              "      <th>months_as_customer_groups_51-100</th>\n",
              "      <th>policy_annual_premium_groups_high</th>\n",
              "      <th>policy_annual_premium_groups_low</th>\n",
              "      <th>policy_annual_premium_groups_medium</th>\n",
              "      <th>policy_annual_premium_groups_very high</th>\n",
              "      <th>policy_annual_premium_groups_very low</th>\n",
              "      <th>policy_deductable_group_0-500</th>\n",
              "      <th>policy_deductable_group_1501-2000</th>\n",
              "      <th>policy_deductable_group_501-1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>446755</td>\n",
              "      <td>0</td>\n",
              "      <td>-46200</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6560</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>4427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>475891</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>8921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>603948</td>\n",
              "      <td>47200</td>\n",
              "      <td>-69700</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>36300</td>\n",
              "      <td>2013</td>\n",
              "      <td>0</td>\n",
              "      <td>205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>462525</td>\n",
              "      <td>26500</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>55200</td>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1980</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>471366</td>\n",
              "      <td>0</td>\n",
              "      <td>-31700</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>48290</td>\n",
              "      <td>1995</td>\n",
              "      <td>0</td>\n",
              "      <td>7692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>604328</td>\n",
              "      <td>0</td>\n",
              "      <td>-47400</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3190</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>8231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>438546</td>\n",
              "      <td>0</td>\n",
              "      <td>-54600</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>72120</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>431354</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>48070</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>2591</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>476737</td>\n",
              "      <td>0</td>\n",
              "      <td>-40900</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>70290</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>6798</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>437470</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>42500</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>5385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>610706</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6500</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>435100</td>\n",
              "      <td>67900</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58500</td>\n",
              "      <td>1999</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>443567</td>\n",
              "      <td>0</td>\n",
              "      <td>-32100</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60200</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>4819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>450800</td>\n",
              "      <td>51100</td>\n",
              "      <td>-75100</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>69400</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>8585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 175 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    insured_zip  ...  policy_deductable_group_501-1000\n",
              "0        446755  ...                               1.0\n",
              "1        475891  ...                               0.0\n",
              "2        603948  ...                               1.0\n",
              "3        462525  ...                               0.0\n",
              "4        471366  ...                               0.0\n",
              "5        604328  ...                               0.0\n",
              "6        438546  ...                               0.0\n",
              "7        431354  ...                               0.0\n",
              "8        476737  ...                               0.0\n",
              "9        437470  ...                               1.0\n",
              "10       610706  ...                               1.0\n",
              "11       435100  ...                               0.0\n",
              "12       443567  ...                               1.0\n",
              "13       450800  ...                               0.0\n",
              "\n",
              "[14 rows x 175 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Bütün kategorik verilere one-hot dönüşümü uygulanması\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Model setine fit ve transform işlemlerinin uygulanması\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_fit = ohe.fit(df1_model[columns_to_encode])\n",
        "enc_fit_arr=enc_fit.fit_transform(df1_model[columns_to_encode]).toarray()\n",
        "\n",
        "# Birleştirme sırasında veri kaybı yaşanmaması için index resetleme\n",
        "df1_dummy.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Encode sonucu oluşan veriler ile orjinal verilerin birleştirilmesi\n",
        "enc_fit_df=pd.DataFrame(enc_fit_arr, columns=clmn_dummy)\n",
        "df1_model_ohe = pd.concat([df1_dummy,enc_fit_df], axis=1)\n",
        "df1_model_ohe.head(14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcIBB_Rl9whJ"
      },
      "source": [
        "<br>Yukarıda model setine one-hot dönüşümü uygulandı, parametre olarak da handle_unknown = 'ignore' verildi. Böylelikle validation setindeki veriler ile uyuşmazlık yaşandığı takdirde çıkacak olan sorunun üstesinden gelmiş olduk.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YxKFElCvfGm",
        "outputId": "8bc7ea9d-a967-47f2-b0f7-b58fd505250d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Kategorik değişken varlığının kontorlü\n",
        "cols = df1_model_ohe.columns\n",
        "num_cols = df1_model_ohe._get_numeric_data().columns\n",
        "list(set(cols) - set(num_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BWFr7h6ZwhZ2"
      },
      "outputs": [],
      "source": [
        "#Feature ve target değişkenlerinin belirlenmesi\n",
        "target = 'fraud_reported'\n",
        "\n",
        "X = df1_model_ohe.drop(columns=target, axis=1)\n",
        "y = df1_model_ohe[target]\n",
        "\n",
        "#Feature'lara scale işlemi uygulanması\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNdShC9k-fa1"
      },
      "source": [
        "<br/>Yukarıda öncelikle elimizde kategorik değişken kalıp kalmadığı kontrol edildi. Bütün değişkenlerin nümerik olduğu tespit edildikten sonra feature ve targerları belirlendi. Sonrasında elimizdeki verileri ölçekleyerek model kurmaya hazır hale getirildi.\n",
        "Bundan sonraki adım ise hedefimizdeki değişkenleri dengeli hale getirmek olacak. Elimizde az sayıda bulunan 1 değişkenini oversampling ile arttırarak 0 ile aynı seviyeye getireceğiz.\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "mTCll_6fw7bq",
        "outputId": "8d7693ca-d245-421b-b765-9c336e3f50bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f625f123f10>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Train/test splitting ve oversampling işlemleri\n",
        "oversample = SMOTE(random_state=9)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,  random_state = 42)\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size = 0.3, random_state = 1)\n",
        "\n",
        "chck = pd.DataFrame()\n",
        "chck['fraud_reported'] = y_train\n",
        "\n",
        "sns.countplot(chck['fraud_reported'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmEu6LFQ_WjJ"
      },
      "source": [
        "<br>\n",
        "Target değişkenlerimizin de dengeli hale geldiğini yukarıdaki grafikten anlayabiliyoruz. Artık elimizdeki test verisini kullanarak, Random Forest ile tahminleme yapıp skor üretebiliriz.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "dMiLZK2iw-Xh",
        "outputId": "a2f4bd46-75eb-42c3-b977-a9a50cecac02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93.25396825396825\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       128\n",
            "           1       0.92      0.94      0.93       124\n",
            "\n",
            "    accuracy                           0.93       252\n",
            "   macro avg       0.93      0.93      0.93       252\n",
            "weighted avg       0.93      0.93      0.93       252\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f625f677e10>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# RFC tanımlanıp tahmin yapılıp skor üretilmesi\n",
        "rfc = RandomForestClassifier(random_state = 1)\n",
        "rfc.fit(X_train, y_train)\n",
        "preds = rfc.predict(X_test)\n",
        "score = rfc.score(X_test, y_test)\n",
        "\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3x4cQgTBSEG"
      },
      "source": [
        "<br>\n",
        "Model setimize encode, scale ve smote işlemlerini uyguladıktan sonra test için ayırdığımız veri seti ile basit bir deneme yaptığımızda 0 ve 1 için güzel tahmin skorları üretebildik. Hyperparameter optimizasyonu ile neler değiştirebileceğimizi aşağıda göreceğiz.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly0E8sWbxRK9",
        "outputId": "c59d03d4-b38a-4ea6-f5de-f82f78c80997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [300, 650, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 17, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   32.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [5, 17, 30, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [300, 650, 1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 1000, num = 3)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 3)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzBtccQgypal",
        "outputId": "43d6c8d8-5c06-426a-9a89-d0bce79f8950"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 5,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 300}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "2lijIBtuyq2U",
        "outputId": "16a816d3-f0c6-4aae-bfa0-5e28ab27944e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91.93548387096774\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92       124\n",
            "           1       0.91      0.94      0.92       124\n",
            "\n",
            "    accuracy                           0.92       248\n",
            "   macro avg       0.92      0.92      0.92       248\n",
            "weighted avg       0.92      0.92      0.92       248\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f62558d2810>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Bulunan best paramsların rfc'ye uygulanması ve tekrardan fit ve tahmin işlemlerinin gerçekleştirilip skor üretilmesi\n",
        "rf2 = RandomForestClassifier(n_estimators=300,min_samples_split=2,min_samples_leaf=2,max_features='auto'\n",
        "                            ,max_depth=5,bootstrap='False')\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "preds = rf2.predict(X_test)\n",
        "\n",
        "score = rf2.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkzc60pKCLpr"
      },
      "source": [
        "<br>\n",
        "Çeşitli parametre değişkenleri denenerek bir çok kez eğitim gerçekleştirildi ve elde edilen skorların bir önceki aşamadaki ile aynı olduğu tespit edildi. Elimizde alabileceğimiz maksimum verim üreten parametrelerle devam edeceğiz. Bundan sonraki aşama ise modelimizi gerçek yaşam simülasyonuna sokmak, evet, validation seti ile modelimizin ne kadar faydalı çalıştığını tespit etmeye çalışacağız. Fakat öncesinde validation setimizi modelimize uygun hale getirmemiz lazım, yani modele ne işlem uygulandıysa aynısını validation setine de uygulamamız gerekmektedir. Bunlar da encode ve scale işlemleri. \n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "816ce4HL6vMp"
      },
      "outputs": [],
      "source": [
        "# KAtegorik verilerin tespiti\n",
        "categorical_cols = ['age_group', 'months_as_customer_groups', 'policy_annual_premium_groups','location_check','policy_deductable_group']\n",
        "for col in categorical_cols:\n",
        "  df1_val[col] = df1_val[col].astype('object')\n",
        "\n",
        "# Encode edilecek olan kolonların belirlenmesi\n",
        "columns_to_encode = []\n",
        "for col in df1_val.columns:\n",
        "  if df1_val[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)\n",
        "\n",
        "# Daha önce oluşturulan enc_fit ile validation setinin de encode edilmesi\n",
        "df1_val_ohe = pd.DataFrame(enc_fit.transform(df1_val[columns_to_encode]).toarray(), columns=clmn_dummy)\n",
        "columns_num = columns_dummy[:11]\n",
        "df1_val_numerical = pd.DataFrame(df1_val, columns=columns_num)\n",
        "df1_val_numerical.reset_index(drop=True, inplace=True)\n",
        "df1_val_ohe = pd.concat([df1_val_numerical, df1_val_ohe], axis=1)\n",
        "\n",
        "# Feature ve targetlerın belirlenmesi\n",
        "target = 'fraud_reported'\n",
        "X_val = df1_val_ohe.drop(columns=target, axis=1)\n",
        "y_val = df1_val_ohe[target]\n",
        "\n",
        "# Feature verilerinin ölçeklendirilmesi\n",
        "X_val = sc.fit_transform(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "macIITdbgboJ",
        "outputId": "5b12697f-db7f-4784-b22d-a8a501496369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27.500000000000004\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.12      0.21       163\n",
            "           1       0.20      0.97      0.33        37\n",
            "\n",
            "    accuracy                           0.28       200\n",
            "   macro avg       0.57      0.54      0.27       200\n",
            "weighted avg       0.81      0.28      0.23       200\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6253f12c50>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train seti ile validation setinin tahminlemesi\n",
        "preds = rf2.predict(X_val)\n",
        "score = rf2.score(X_val, y_val)\n",
        "\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_val, preds))\n",
        "\n",
        "cm = confusion_matrix(y_val, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3xItMAJDrcl"
      },
      "source": [
        "<br>\n",
        "Validasyon verilerine yukarıda bahsedilen işlemler uygulandıktan sonra modelimizin gerçek hayatta nasıl bir performans sergilediğini yukarıda görmekteyiz. Daha öncesinde yüzde 91 olan 0 tahminleme skoru yüzde 12 değerine kadar gerilemiş. Gerçek hayatta sıfırları tahminlemede oldukça kötü bir performans sergilediğini görüyoruz. Peki burda neyi yanlış yaptık ya da neyi değiştirebiliriz? Belki kullandığımız algoritma ya da yanlış verilerin gruplanması... vb. bir çok etken buna sebep olabilir. En basit yoldan bir şeyi değiştirebilir, o da threshold değeri. Bu değer ile oynayarak nasıl bir çıktı alacağımızı kontrol edelim.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "m8jEHoiWhO8M",
        "outputId": "a5466b6a-9f09-4c1c-9be1-be664e5b2513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27.500000000000004\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.72      0.82       163\n",
            "           1       0.40      0.81      0.54        37\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.67      0.77      0.68       200\n",
            "weighted avg       0.84      0.74      0.77       200\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f62558e0150>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Threhold değerine müdahelede bulunulması ve sonrasında tekrardan skor üretilmesi\n",
        "preds = (rf2.predict_proba(X_val)[:,1] >= 0.62).astype(int)\n",
        "score = rf2.score(X_val, y_val)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_val, preds))\n",
        "\n",
        "cm = confusion_matrix(y_val, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTpcvb8NEe2h"
      },
      "source": [
        "<br>\n",
        "Threshold değerimiz ile oynadığımızda özellikle 0 tahminlemede ciddi bir ilerleme kaydettiğimizi görüyoruz fakat 1 tahminlemede de ufak bir kaybımız var. Modelin bu haliyle bir öncekine oranla daha iyi olduğunu söyleyebiliriz fakat hala mükemmel değil. Peki mükemmel olması için başka ne yapılabilir? Train/test splitte çeşitli yöntemler uygulanabilir, farklı algoritmalar denenebilir ya da encoding yöntemleri değiştirilebilir. \n",
        "Öncelikle farklı algoritmalar ile farklı sonuçlar üretilebileceğimiz bir gerçek fakat bizim burdaki amacımız farklı algoritmaları denemekten ziyade gerçekleştireceğimiz diğer işlemler ile aynı algoritma üzerinde daha fazla skor üretebilmek. \n",
        "Genel olarak veri setine komple label encoding yapmak pek doğru gelmemektedir, sebebi ise label encodingin çalışma mantığı. Belirli kategoriler belirleyip onlara ayrıca uygulamak mantıklı olabilir fakat tek seferde bütün kategorik değişkenlere uygulanabilecek en mantıklı yöntem one-hot encoding. Bu seçeneği de elediğimize göre, smote'da ki state adımı ve train test split parametrelerinde değişikliklerle skorumuzu yükseltmeyi deneyelim.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "oXh-kDlR7Bmo",
        "outputId": "54736560-d4b9-4ff2-83cf-a6f60221d1d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90.7258064516129\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       124\n",
            "           1       0.91      0.90      0.91       124\n",
            "\n",
            "    accuracy                           0.91       248\n",
            "   macro avg       0.91      0.91      0.91       248\n",
            "weighted avg       0.91      0.91      0.91       248\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f62545b5c90>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "oversample = SMOTE(random_state=20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3,  random_state = 42)\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, stratify=y_over, test_size = 0.3, random_state = 1)\n",
        "\n",
        "chck = pd.DataFrame()\n",
        "chck['fraud_reported'] = y_train\n",
        "\n",
        "\n",
        "rfc = RandomForestClassifier(random_state = 1)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "preds = rfc.predict(X_test)\n",
        "\n",
        "score = rfc.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efWNeN9A7H9U",
        "outputId": "21a4c5ce-9c85-46f0-90bf-ba9a5dbf28ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 164, 228, 292, 357, 421, 485, 550, 614, 678, 742, 807, 871, 935, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 8, 11, 14, 17, 20, 23, 26, 30, None], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   38.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [5, 8, 11, 14, 17, 20, 23,\n",
              "                                                      26, 30, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10, 15],\n",
              "                                        'n_estimators': [100, 164, 228, 292,\n",
              "                                                         357, 421, 485, 550,\n",
              "                                                         614, 678, 742, 807,\n",
              "                                                         871, 935, 1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 15)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 9)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 15]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnMlV8dq8iHR",
        "outputId": "cf787d60-8927-47a9-8745-dfcb8a37091c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 26,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 807}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aEMowhwK8n_9",
        "outputId": "062aaa65-5113-41be-9404-0234904b4bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90.7258064516129\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91       124\n",
            "           1       0.90      0.91      0.91       124\n",
            "\n",
            "    accuracy                           0.91       248\n",
            "   macro avg       0.91      0.91      0.91       248\n",
            "weighted avg       0.91      0.91      0.91       248\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6254146810>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATdUlEQVR4nO3de5hVdbnA8e87IKdSuQiiBmqmZlqZmk/Z4zlmYuYtRS2ElFCxMc1rpOKlDAu1TEyPGs3JC1qSZnowu4l45ViT97s9EmWAXLzhXYaZ/Tt/zH5okIHZs5mZH3vx/fD8ntn7t9as9Q7PPC8v7/qttSOlhCSp59XlDkCS1lYmYEnKxAQsSZmYgCUpExOwJGXSu7tPsHTh31xmoRWsu9mw3CFoDdS0ZG6s7jGWvjS74pyzzqAPr/b5VocVsCRl0u0VsCT1qFJL7ggqZgKWVCwtzbkjqJgJWFKhpFTKHULFTMCSiqVkApakPKyAJSkTL8JJUiZWwJKUR3IVhCRl4kU4ScrEFoQkZeJFOEnKxApYkjLxIpwkZeJFOEnKIyV7wJKUhz1gScrEFoQkZWIFLEmZtCzNHUHFTMCSisUWhCRlYgtCkjKxApakTGooAdflDkCSulJqWVrx6EhEXBURiyLiyTZzG0TE9Ih4rvx1QHk+IuLSiJgVEY9HxE4dHd8ELKlYUqny0bFrgL3fMzcemJFS2hqYUX4PsA+wdXnUAz/t6OAmYEnFUipVPjqQUroXeOU90wcCU8qvpwDD28xfm1r9BegfEZus6vgmYEnF0okKOCLqI+LBNqO+gjNslFKaX369ANio/HoIMKfNfnPLcyvlRThJxdKJi3AppQagodpTpZRSRKRqv98ELKlYun8d8MKI2CSlNL/cYlhUnp8HbNpmv6HluZWyBSGpWJqbKx/VuRUYU349BpjWZv5r5dUQuwCvtWlVtMsKWFKxdGEFHBFTgd2BQRExFzgHuAC4MSLGAs8DI8q7/x7YF5gFvA0c2dHxTcCSiqULb8RIKY1ayaZh7eybgG925vgmYEnF4rMgJCmTGroV2QQsqVisgCUpk+pXN/Q4E7CkYklV3xfR40zAkorFHrAkZWIClqRMvAgnSZm0tOSOoGImYEnFYgtCkjIxAUtSJvaAJSmPVHIdsCTlYQtCkjJxFYQkZWIFLEmZ1FAC9jPhVuHsCy5htwNGM3zM8e1un/38XA479lR2HHYwV0+9pUvO2dS0lHHn/Ih9RtUz6phvM2/+QgDuf+ARRhx9CgeNOYERR59C40OPdcn51LMafvZj5s55lEcevmPZ3Pnnn80Tj9/NQw9O59c3/px+/fpmjLAAUqp8ZGYCXoXhew9j8oXfW+n2fn3XY/yJ9Rwx8qBOH3ve/IUcceKZK8zf/Lvp9F1/Pf4wtYHRIw5g0uQpAAzo15fLLjibW6b8NxPPPJkzJl7c6XMqv2uv+zX7f+nw5eZmzLiXHXYcxqd2/gLPPTeb009r/x98VahUqnxkZgJehZ13+Dj9+q630u0DB/TnE9tuTe9evVbY9tvb72Jk/TgOOeokJlx4OS0VXhi4c2YjB+69BwB7fW5XGh9+jJQS235kSwYPGgjAVltsxrtLmmhqWlrFT6WcZs5s5NVXFy83d8cd9y77/WhsfJghQzbJEVpxlFLlI7MOE3BEfDQiTo+IS8vj9IjYtieCq1V//+cc/njnTK674of85qpLqOtVx23T76noexe99DIbDx4EQO/evVhv3XVZ/Noby+0z/Z772e4jW9KnzzpdHrvyOuKIQ/nTn+7KHUZta2mpfGS2yotwEXE6MAr4FfDX8vRQYGpE/CqldMFKvq8eqAe44sIJHD360K6LuAY0PvQYT//t74ysHwfAkiVNbNC/HwAnnnUe8+YvZOnSZuYvepFDjjoJgMO//CUO2nfPDo896x//YtLkKTRcNKH7fgBlMf70E2hubuH6qTfnDqWmpTWgtVCpjlZBjAU+llJa7v+6ETEJeApoNwGnlBqABoClC/+Wv87vYQk4YO/Pc8oxY1bYdunE1r7vvPkLOev8S7jm0vOW2z540EAWLHqJjQcPorm5hTffeov+/dYHYMGilzjprPM476yT2cz/phbK6NFfYd999+SLe69dxUq3WANaC5XqqAVRAj7Yzvwm5W1qxy6f2p7pd9/Py+Ve32uvv8ELCxZV9L2f3/XTTPvjnQDcfs//8ZmdticieP2NNznu9HM5+ZivsdMntuu22NXz9tprd7497lgOPuRI3nnn3dzh1L5Uqnxk1lEFfDIwIyKeA+aU5zYDtgIKf6n21AkX8sAjT7L4tdcZdsiRHHfkKJrLfaNDD9yHl15+lUPrv8Wbb71NXV0dv7jpVqZdezlbfmgzTjj6cOrHnUOpVGKd3r0565Rj+ODGgzs858H7fYEzJk5in1H19Ft/fS783qkATL35d8yZN5/JU25g8pQbAGi4aAIDB/Tvvr8Adbnrrr2M3Xb7LIMGbcDsvz/Aud+/iNNOO57/6NOHP/x+KgCNf32Y448/I3OkNayGKuBIHayFi4g64NPAkPLUPOCBlFJFHey1sQWhjq272bDcIWgN1LRkbqzuMd767siKc8665/5qtc+3Ojq8Ey6lVAL+0gOxSNLqWwNaC5XyVmRJxVJDLQgTsKRCKdIyNEmqLVbAkpSJCViSMlkDbjGulAlYUqH4mXCSlEsNJWAfRympWLrwecARcUpEPBURT0bE1Ih4X0RsERGNETErIm6IiD7VhmoCllQsXfQ84IgYApwI7JxS+jjQCxgJ/BC4OKW0FfAqrQ8tq4oJWFKxdO0D2XsD74+I3sAHgPnAHsBN5e1TgOHVhmoCllQoqaVU8YiI+oh4sM2oX3aclOYBPwb+RWvifQ14CFicUmou7zaXfz8np9O8CCepWDpxEa7ts8vfKyIGAAcCWwCLgV8De3dBhMuYgCUVShcuQ9sT+EdK6UWAiLgZ2BXoHxG9y1XwUFqfEFkVWxCSiqXresD/AnaJiA9ERADDgKeBu4Avl/cZA0yrNlQTsKRiKXVirEJKqZHWi20PA0/Qmi8bgNOBb0XELGAgcGW1odqCkFQoqbnrnoaWUjoHOOc907Np/ZCK1WYCllQstfM0ShOwpGLxWRCSlIsVsCTlYQUsSblYAUtSHstuEq4BJmBJhVJDn0pvApZUMCZgScrDCliSMjEBS1ImqSVyh1AxE7CkQrEClqRMUskKWJKysAKWpExSsgKWpCysgCUpk5KrICQpDy/CSVImJmBJyiTVzuOATcCSisUKWJIycRmaJGXS4ioIScrDCliSMrEHLEmZuApCkjKxApakTFpKdblDqJgJWFKh2IKQpExKroKQpDxchiZJmdiCaOP9m+7R3adQDXrnhftyh6CCqqUWRO1cLpSkCrSU6ioeHYmI/hFxU0Q8GxHPRMRnI2KDiJgeEc+Vvw6oNlYTsKRCSZ0YFbgE+GNK6aPAJ4FngPHAjJTS1sCM8vuqmIAlFUopRcVjVSKiH7AbcCVASqkppbQYOBCYUt5tCjC82lhNwJIKJaWoeEREfUQ82GbUtznUFsCLwNUR8UhE/Dwi1gU2SinNL++zANio2lhdBSGpUDrzocgppQagYSWbewM7ASeklBoj4hLe025IKaWIqHrdhRWwpEJJRMWjA3OBuSmlxvL7m2hNyAsjYhOA8tdF1cZqApZUKM0pKh6rklJaAMyJiG3KU8OAp4FbgTHluTHAtGpjtQUhqVAqqGw74wTglxHRB5gNHElr4XpjRIwFngdGVHtwE7CkQulMD7gjKaVHgZ3b2TSsK45vApZUKF1cAXcrE7CkQunKCri7mYAlFUqLFbAk5VFDn0hkApZULCUrYEnKo4YeB2wCllQsXoSTpExKYQtCkrJoyR1AJ5iAJRWKqyAkKRNXQUhSJq6CkKRMbEFIUiYuQ5OkTFqsgCUpDytgScrEBCxJmXTwUW9rFBOwpEKxApakTLwVWZIycR2wJGViC0KSMjEBS1ImPgtCkjKxByxJmbgKQpIyKdVQE8IELKlQvAgnSZnUTv1rApZUMFbAkpRJc9RODWwCllQotZN+TcCSCsYWhCRlUkvL0OpyByBJXSl1YlQiInpFxCMRcVv5/RYR0RgRsyLihojoU22sJmBJhVLqxKjQScAzbd7/ELg4pbQV8CowttpYTcCSCqWFVPHoSEQMBfYDfl5+H8AewE3lXaYAw6uN1QQsqVA6UwFHRH1EPNhm1L/ncD8BTuPfBfNAYHFKqbn8fi4wpNpYvQgnqVBSJy7CpZQagIb2tkXE/sCilNJDEbF710S3PBOwpELpwmVouwIHRMS+wPuAvsAlQP+I6F2ugocC86o9gS2IbvI/DRfxwtzHePSRGcvmDjlkfx579E6a3p3Dp3baPmN0Wh1nnzeJ3fYbyfDDv9Hu9tnPz+Gw+lPYcfcvcfX1N7W7T2c1NTUx7jvns8+Ioxj19ZOZN38hAPf/9WFGHHUCB40+lhFHnUDjQ492yflqWYlU8ViVlNIZKaWhKaUPASOBO1NKhwF3AV8u7zYGmFZtrCbgbnLttTey3/6HLTf31FPP8pURX+e++/6SKSp1heH7foHJk36w0u39+q7P+FO+wRGjDun0sefNX8gRx5+2wvzNt91O3/XX4w83XsXoQ4cz6YqrABjQvy+X/fB73HLdT5l49jjOOPfHnT5n0XT1MrR2nA58KyJm0doTvrLaA9mC6Cb3zWxk882HLjf37LOzMkWjrrTzDp9YVoG2Z+CA/gwc0J97739ghW2//dOd/PLX01i6tJntP7YNZ4/7Jr169erwnHfe92eOG3s4AHvt/l+cN+mnpJTY9iNbLdtnqy02590lS2hqaqJPn6qXpta85m64ESOldDdwd/n1bODTXXFcK2Cph/z9n//ijzPu4brJF/GbKZdTV1fHbbffVdH3LnrxZTYePAiA3r17sd66H2Dxa68vt8/0u2ey3TZbrdXJF1ovwlX6J7eqK+CIODKldPVKttUD9QDRqx91detWexqpMBoffJSnn53FyLEnAbBkyRI2GNAfgBPPOJd5LyxkafNS5i98kUPGfBOAw0ccyEH77dXhsWfNfp5JV1xFw8UTu+8HqBFry7MgJgDtJuC2Szt69xmS/58ZaQ2QUuKAffbklGOPXGHbped/F2jtAZ818SKuuexHy20fvOFAFix6iY0Hb0hzcwtvvvU2/fv1BWDBohc56czvc953vs1mQz/Y/T/IGm5NqGwrtcoWREQ8vpLxBLBRD8UoFcIuO+/A9Ltn8vKriwF47fU3eGHBynvJbX3+P3dh2u/vAOD2u+/jM5/6JBHB62+8yXGnnsPJ3ziSnbb/WLfFXku64VbkbtNRBbwR8EVa73duK4D7uyWigvjFdZfzud0+y6BBG/DP2Q8y4dwf88qri7nk4h+w4YYbcOu0a3nssafY9z0rJbTmO/WcC3jgkcdZvPh1hg0/nOPGjqa5ufXGqEMP2o+XXn6FQ8eeyJtvvU1dXR2/uPF/mfbLn7HlFptzwte/Rv3JZ1FKJdbp3ZuzvnUcH9y441rm4P2/yBnfv5B9RhxFv77rc+GE8QBM/c1vmTP3BSZffT2Tr74egIafTGRgubWxNmpJtVMBR1pFsBFxJXB1SmlmO9uuTyl9taMT2IJQe9554b7cIWgNtM6gD8fqHuOrmx9Ucc65/vlbVvt8q2OVFXBKaaVP+akk+UpST6ulHrDrgCUVyprQ262UCVhSodTSJ2KYgCUVii0IScqkllZBmIAlFYotCEnKxItwkpSJPWBJysQWhCRlsqq7e9c0JmBJhVLJx82vKUzAkgrFFoQkZWILQpIysQKWpExchiZJmXgrsiRlYgtCkjIxAUtSJq6CkKRMrIAlKRNXQUhSJi2pdh5IaQKWVCj2gCUpE3vAkpSJPWBJyqRkC0KS8qilCrgudwCS1JVaUqnisSoRsWlE3BURT0fEUxFxUnl+g4iYHhHPlb8OqDZWE7CkQimlVPHoQDMwLqW0HbAL8M2I2A4YD8xIKW0NzCi/r4oJWFKhpE78WeVxUpqfUnq4/PoN4BlgCHAgMKW82xRgeLWx2gOWVCjdcREuIj4E7Ag0AhullOaXNy0ANqr2uFbAkgqlMxVwRNRHxINtRv17jxcR6wG/AU5OKb2+3Lla7/qoOuNbAUsqlJbUUvG+KaUGoGFl2yNiHVqT7y9TSjeXpxdGxCYppfkRsQmwqNpYrYAlFUpKqeKxKhERwJXAMymlSW023QqMKb8eA0yrNlYrYEmF0oW3Iu8KjAaeiIhHy3NnAhcAN0bEWOB5YES1JzABSyqUrnoYT0ppJhAr2TysK85hApZUKN6KLEmZ1NKtyCZgSYXiA9klKRMfyC5JmdgDlqRMrIAlKRM/kkiSMrEClqRMXAUhSZl4EU6SMrEFIUmZeCecJGViBSxJmdRSDzhq6V+LWhcR9eUn8EvL+Hux9vITMXrWCp83JeHvxVrLBCxJmZiAJSkTE3DPss+n9vh7sZbyIpwkZWIFLEmZmIAlKRMTcA+JiL0j4m8RMSsixueOR/lFxFURsSginswdi/IwAfeAiOgFXA7sA2wHjIqI7fJGpTXANcDeuYNQPibgnvFpYFZKaXZKqQn4FXBg5piUWUrpXuCV3HEoHxNwzxgCzGnzfm55TtJazAQsSZmYgHvGPGDTNu+HluckrcVMwD3jAWDriNgiIvoAI4FbM8ckKTMTcA9IKTUDxwN/Ap4BbkwpPZU3KuUWEVOBPwPbRMTciBibOyb1LG9FlqRMrIAlKRMTsCRlYgKWpExMwJKUiQlYkjIxAUtSJiZgScrk/wHBqKGKuI8FSgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rf2 = RandomForestClassifier(n_estimators=807,min_samples_split=2,min_samples_leaf=1,max_features='auto'\n",
        "                            ,max_depth=26,bootstrap='True')\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "preds = rf2.predict(X_test)\n",
        "\n",
        "score = rf2.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "AQTHNY3i8yR0",
        "outputId": "a47227ef-07c8-4142-cf2e-935f417fbfbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49.5\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.40      0.57       163\n",
            "           1       0.25      0.89      0.40        37\n",
            "\n",
            "    accuracy                           0.49       200\n",
            "   macro avg       0.60      0.65      0.48       200\n",
            "weighted avg       0.82      0.49      0.53       200\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f62541464d0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "categorical_cols = ['age_group', 'months_as_customer_groups', 'policy_annual_premium_groups','location_check','policy_deductable_group']\n",
        "for col in categorical_cols:\n",
        "  df1_val[col] = df1_val[col].astype('object')\n",
        "\n",
        "columns_to_encode = []\n",
        "for col in df1_val.columns:\n",
        "  if df1_val[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)\n",
        "\n",
        "df1_val_ohe = pd.DataFrame(enc_fit.transform(df1_val[columns_to_encode]).toarray(), columns=clmn_dummy)\n",
        "columns_num = columns_dummy[:11]\n",
        "df1_val_numerical = pd.DataFrame(df1_val, columns=columns_num)\n",
        "df1_val_numerical.reset_index(drop=True, inplace=True)\n",
        "df1_val_ohe = pd.concat([df1_val_numerical, df1_val_ohe], axis=1)\n",
        "\n",
        "target = 'fraud_reported'\n",
        "\n",
        "X_val = df1_val_ohe.drop(columns=target, axis=1)\n",
        "y_val = df1_val_ohe[target]\n",
        "\n",
        "X_val = sc.fit_transform(X_val)\n",
        "\n",
        "preds = rf2.predict(X_val)\n",
        "score = rf2.score(X_val, y_val)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_val, preds))\n",
        "\n",
        "cm = confusion_matrix(y_val, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "66rX53fi9M-y",
        "outputId": "7d97dd49-b4a5-4435-a396-0384d9bb097c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27.500000000000004\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.72      0.82       163\n",
            "           1       0.40      0.81      0.54        37\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.67      0.77      0.68       200\n",
            "weighted avg       0.84      0.74      0.77       200\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6253fe71d0>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "preds = (rf2.predict_proba(X_val)[:,1] >= 0.62).astype(int)\n",
        "score = rf2.score(X_val, y_val)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_val, preds))\n",
        "\n",
        "cm = confusion_matrix(y_val, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BCCbd8YUc_j"
      },
      "source": [
        "<br>\n",
        "Train/test split metoduna eklediğimiz stratify parametresinin ve smote işleminde gerçekleştirilen randome state sayısının değiştirilmesi sonucunda elde ettiğimiz skor yukarıda yer almaktadır. Bu skor bir önceki ile birebir aynıdır, bu da demek oluyor ki bu işlemler de ekstradan bir fayda sağlamadı. Fakat skorlarımız genel olarak daha iyi durumdalar.\n",
        "Peki tüm bu işlemlerden çıkarılacak olan sonuç nedir? Modelin gerçek hayatta göstermiş olduğu performans neye bağlıdır? Aslında tüm bunların cevabını bir nebze bu çalışmada vermiş olduk. Öncelikle önemli olan ilk şey, validation setinin (bazı kaynaklarda test olarak geçer), modelin görmediği veri, ilk başta herhangi bir işleme uğramadan tüm eğitim sonuna kadar saklanması gerekmektedir. Daha sonrasında eğitecek olduğumuz veri setini rastgeleden ziyade daha dengeli parçalamılıyız, böylelikle tek bir değer üzerine yoğunlaşmanın önüne geçmiş oluruz. Encoding yöntemlerini ilgili kolonların türüne ve anlamlarına göre uygulamalıyız ve burdaki en önemli nokta, saklamış olduğumuz validation setinde olmayan ya da orda olup eğitim setinde olmayan verileri dikkate alarak encoding işlemi gerçekleştirmeliyiz. Aksi takdirde validation ile tahminlemede hiç görmediği bir veri ile karşılaşabilir ve modelin kafasını karıştırabiliriz. Bunlar dışında hyperparameter değerlerinin önemi de fazladır. Tabii en önemli noktalardan birisi de hangi yöntemi kullanacağımız. RFC mi SVM mi vb. bir çok sınıflandırma algoritması bulunmaktadır. Bunları modelimiz üzerinde test ederek karşılaştırabilir ve hangisin daha uygun olduğunu belirleyebiliriz. Bu çalışmada algoritma denemekten ziyade diğer parametreler üzerinde iyileştirmeler yapılması amaçlanmıştır.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Q6.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
